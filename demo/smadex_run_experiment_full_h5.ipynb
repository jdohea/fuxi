{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import logging\n",
    "from fuxictr import datasets\n",
    "from datetime import datetime\n",
    "from fuxictr.utils import load_config, set_logger, print_to_json\n",
    "from fuxictr.features import FeatureMap\n",
    "from fuxictr.pytorch.torch_utils import seed_everything\n",
    "from fuxictr.pytorch.dataloaders import H5DataLoader\n",
    "from model_zoo import DeepFM\n",
    "import pickle\n",
    "# ^^suppress output\n",
    "\n",
    "# Load params from config files\n",
    "config_dir = './config/full_h5_config'\n",
    "experiment_id = 'full_h5_initial' # corresponds to h5 input `data/tiny_h5`\n",
    "params = load_config(config_dir, experiment_id)\n",
    "\n",
    "# set up logger and random seed\n",
    "set_logger(params)\n",
    "logging.info(\"Params: \" + print_to_json(params))\n",
    "seed_everything(seed=params['seed'])\n",
    "\n",
    "# Load feature_map from json\n",
    "data_dir = os.path.join(params['data_root'], params['dataset_id'])\n",
    "feature_map_json = os.path.join(data_dir, \"feature_map.json\")\n",
    "feature_map = FeatureMap(params['dataset_id'], data_dir)\n",
    "_ = feature_map.load(feature_map_json, params)\n",
    "_ = logging.info(\"Feature specs: \" + print_to_json(feature_map.features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 19:16:57,136 P22431 INFO Loading data...\n",
      "2023-05-07 19:16:57,141 P22431 INFO Loading data from h5: ../data/full_h5/smadex_train.h5\n",
      "2023-05-07 19:20:20,177 P22431 INFO Train samples: total/307843, blocks/1\n",
      "2023-05-07 19:20:20,192 P22431 INFO Loading data from h5: ../data/full_h5/smadex_val.h5\n",
      "2023-05-07 19:23:13,358 P22431 INFO Validation samples: total/241205, blocks/1\n",
      "2023-05-07 19:23:13,383 P22431 INFO Loading train and validation data done.\n"
     ]
    }
   ],
   "source": [
    "# Get train and validation data generators from h5\n",
    "train_gen, valid_gen = H5DataLoader(feature_map,\n",
    "                                    stage='train',\n",
    "                                    train_data=params['train_data'],\n",
    "                                    valid_data=params['valid_data'],\n",
    "                                    batch_size=params['batch_size'],\n",
    "                                    shuffle=params['shuffle']).make_iterator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_gen.pkl', 'wb') as outp:\n",
    "    pickle.dump(train_gen, outp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "del train_gen\n",
    "\n",
    "with open('train_gen.pkl', 'rb') as inp:\n",
    "    train_gen = pickle.load(inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('valid.pkl', 'wb') as outp:\n",
    "    pickle.dump(valid_gen, outp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "del valid_gen\n",
    "\n",
    "with open('valid.pkl', 'rb') as inp:\n",
    "    valid_gen = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_gen.pkl', 'rb') as inp:\n",
    "    train_gen = pickle.load(inp)\n",
    "\n",
    "with open('valid.pkl', 'rb') as inp:\n",
    "    valid_gen = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1885/1885 [01:51<00:00, 16.95it/s]\n",
      "100%|██████████| 2406/2406 [20:19<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "  # Model initialization and fitting\n",
    "model = DeepFM(feature_map, **params)\n",
    "model.fit(train_gen, validation_data=valid_gen, epochs=params['epochs'])\n",
    "logging.info('***** Validation evaluation *****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as outp:\n",
    "    pickle.dump(model, outp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'rb') as inp:\n",
    "    model = pickle.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1885/1885 [01:50<00:00, 17.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.13082252e-09, 2.73190963e-08, 2.38500100e-08, ...,\n",
       "       5.25770139e-09, 2.38784121e-08, 6.35501820e-08])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(valid_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_true=[]\n",
    "for batch_data in valid_gen:\n",
    "    y_true.extend(model.get_labels(batch_data).data.cpu().numpy().reshape(-1))\n",
    "y_true = np.array(y_true, np.float64)\n",
    "valid_weights = []\n",
    "\n",
    "y_valid = y_true\n",
    "for t in y_valid:\n",
    "    if t == 0:\n",
    "        valid_weights.append(200)\n",
    "    else:\n",
    "        valid_weights.append(1)\n",
    "\n",
    "def real_prob(k,p):\n",
    "    if p == 0:\n",
    "        return 0\n",
    "    return 1/(1-k+(k/p))\n",
    "from sklearn.metrics import log_loss\n",
    "baseline_ll = log_loss(y_valid, [real_prob(200,np.mean(y_valid))]*len(y_valid), sample_weight=valid_weights)\n",
    "model_ll = log_loss(y_valid, y_pred, sample_weight=valid_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL:  0.996097080829555\n"
     ]
    }
   ],
   "source": [
    "print('NLL: ', 1 - model_ll/baseline_ll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
